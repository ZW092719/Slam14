# 神经网络

## 输入

数学表示：

![image-20240911192833959](C:\Users\zbw\AppData\Roaming\Typora\typora-user-images\image-20240911192833959.png)

比如一张32长，32宽的图像。他应该为(32,32,3)的张量

最后的3为R,G,B

那么输入x的大小为：（3072（=32x32x3），1）的向量

比如想做10分类：那么要计算每个分类下的得分（概率），那么**权重矩阵W**为（10，3072）大小的；

另外还有一个偏置，其大小与输出结果矩阵大小的规模一样。

在神经网络中输入输出不再是一个数而是**矩阵**！

关于权重参数：

> 1.权重参数初始化是比较小的
>
> 2.每个数都是独立的独自更新
>
> 3.得到的输出如果并不“好”，那么需要调整权重

### 关于输入矩阵的大小问题

**实际实现（如框架中的处理）**：大部分框架中，输入数据是多个样本的集合，通常会用行向量来表示每个样本，这样每个批次的输入是一个大小为 `batch_size × feature_size` 的矩阵。

**数学推导**：为了方便推导，很多时候会将单个样本表示为列向量，但实际上可以等效地将其转置成行向量（只要矩阵乘法的操作方向是对的，结果是不变的）。

## 损失函数

1.**概念**

那么如何去衡量得到结果的好坏，就此引入损失函数！

通俗的说就是用算出的结果（预测得到的结果）减去真实结果（正确的结果），这便是损失函数

损失越小越好

> 关于标准化，并不是说标签一定不标准化，要看具体的拟合结果，是可以对标签进行标准化的。

**2.损失值相同时该如何衡量模型？**

比如一组权重1，0，0，0；另一组1/4，1/4，1/4，1/4

那么显然第二组模型是更好的他的权重更为平均，更能观察到全部特征，避免过拟合，具有好的泛化能力。

出现了权重特大的情况很可能是具有离群点，

另一个概念惩罚可以让模型在离群部分收敛一点

总结出来：

**损失函数 = 数据损失+正则化惩罚项**

数据损失与正则化惩罚实际上是矛盾的两个方向



## Softmax分类器

通过一个函数把一个得分值转换为一个0~1的概率值

例如函数：
$$
g(z)=\frac{1}{1+e^{-z}}
$$
又例如
$$
P(Y=k|X=x_{i})={\frac{e^{s_{k}}}{\sum_{j}e^{s_{j}}}}
$$
在分类问题中得到了概率我们又要进一步的去计算损失，在图像分类中我们肯定希望得到的概率是越接近1越好，于是可引入对数的一个操作

同样这只是针对图像分类这个问题，不同的模型有不同的损失函数

## 前向传播

前向传播是从前向后得出结果的过程。

前向传播是得出了损失，那么该如何根据损失来调整权重参数



## 反向传播

根据损失来调整权重这便要交给反向传播了（比如梯度下降）

逐层传递链式法则！

底层目前不用太注意，明白意思会用！



## 神经网络的整体结构

![image-20240911203459225](C:\Users\zbw\AppData\Roaming\Typora\typora-user-images\image-20240911203459225.png)

**输入层：**

输入的神经元可以当作特征，比如对于图像输入的就是像素

**隐层：**

将这些特征转换为计算机所能分析识别的数据！

**全连接：**

而特征需要通过**权重组合**与这些隐层所连接起来

**非线性：**

即激活函数，他应用在每一个神经元上，在每个神经元得到上一层的线性组合结过后需要再通过一个非线性函数

因为如果不用激活函数，每一层输出都是上层输入的线性函数，无论神经网络有多少层，输出都是输入的线性组合，这种情况就是最原始的[感知机](https://baike.baidu.com/item/感知机/12723581)（Perceptron）。

![image-20240911214255946](C:\Users\zbw\AppData\Roaming\Typora\typora-user-images\image-20240911214255946.png)

Sigmoid：
$$
\boxed{\sigma(x)=1/(1+e^{-x})}
$$
Relu：
$$
\sigma(x)=\max(0,x)
$$
Sigmoid被淘汰了基本，因为后面其梯度为0不再更新了

**神经元：**

神经元越多模型做的越复杂越能解决更为复杂的东西



## DROP-OUT





# CNN

## 与传统网络的区别

![image-20240912181724966](C:\Users\zbw\AppData\Roaming\Typora\typora-user-images\image-20240912181724966.png)

全连接，MLP，wx+b说的都是传统网络

传统的网络只适合做结构化数据，比如一个人对应几个特征，又一个人对应几个特征，不适合做图像的数据，因为**参数量太大了**

 因此需要CNN

## 整体结构

### **卷积做了什么事**：

与传统的结构数据不同，结构数据的列与列之间可看作是无关联的，但是图像数据不一样

一张图像32x32x3，首先将其切割为很多区域，每个**区域**得到一个特征，这样的操作大大减小计算量！

**卷积核**：二维的矩阵
**[滤波器](https://so.csdn.net/so/search?q=滤波器&spm=1001.2101.3001.7020)：**多个卷积核组成的三维矩阵，多出的一维是通道。

> 例如，在一个输入具有多个通道（如 RGB 图像的 3 个通道）时，每个滤波器实际上包含多个卷积核，每个卷积核对应一个输入通道：
>
> 滤波器={K1,K2,K3}
>
> 其中， **K1,K2,K3**分别是 3 个卷积核，对应于输入图像的 3 个通道
>
> **在有的文档里把卷积核也叫做滤波器两者一回事？**

比如做了一个区域，卷积核或叫filter（滤波器）5x5x3

> 关于**卷积核**的选择：
>
> 一般选择3x3大小
>
> 1.3x3是为了做的更为细致，得到更多的特征
>
> 2.显卡对3x3支持最好
>
> 一般来说**卷积核个数越多越好**！
>
> **有几个卷积核就会得到几个特征图**

最后的3对应的就是RGB三个通道，卷积核或叫滤波器最后的一个维度一定要与输入图像的channel对应！

在每个区域都可得到一个特征点，这些特征点组合到一起就得到了特征图！
![image-20240912211901946](C:\Users\zbw\AppData\Roaming\Typora\typora-user-images\image-20240912211901946.png)

两个卷积核或叫**filter**就可得到两个特征图！

有几个filter就可以得到几个特征图

> filter选择一般越多越好



### 具体计算：

![image-20240912212707314](C:\Users\zbw\AppData\Roaming\Typora\typora-user-images\image-20240912212707314.png)

求卷积核矩阵与图像所提取区域矩阵的**内积**，**对应位置相乘再求和**

求出三个通道的值后，加上偏置一起求和！

> 一个滤波器具有三个卷积核，对于每个卷积核将他们与图像中的区域做内积求和就会得到一个具体的数，**三个卷积核就会得到3个不同的数**，将这三个数再添一个偏置对他们求和就可得到**图像一个区域所得到的特征结果**

注意卷积核的权重是一直不变的，变的是输入即**图像区域**一直在变

> 关于图像区域移动单元格**（stride）**的选择：
>
> 一般stride = 1
>
> **移动的越小越好**，越小越精细，得到特征越丰富

比如第一个卷积核我们要找颜色鲜艳的地方，第二个卷积核要找颜色暗淡的地方，每个卷积核要找的特征不一样。但具体对计算机来说是如何提取的我们不知道，类似于pca

#### 公式

长度：
$$
H_2=\frac{H_1-F_H+2P}{S}+1
$$
H2为输出，H1为输入，FH为卷积核大小，p为padding，S为stride步长

宽度：
$$
\mathrm{W}_{2}=\frac{\mathrm{W}_{1}-\mathrm{F}_{W}+2\mathrm{P}}{\mathrm{s}}+1
$$
例如：输入数据为32x32x3的图像，用10个5x5x3的filter来进行卷积操作，指定步长为1，边界填充为2，最终的输出规模为？

长度宽度为：

（32-5+2x2）/1 + 1 = 32

另外有10个filter，所以输出规模为32x32x10

**即经过卷积操作后也可以保持特征图的长度宽度不变**，大部分都是不变的









### 卷积的注意事项

1.越靠近图像中间的区域被卷积的次数越多，而边上的区域被卷积的次数会少，因此有一定不公平

> 如何解决：
>
> 在原区域的边界外围再加上一圈东西并让这一圈都**为0**，这个变量就叫做padding
>
> 这样的话原本外围的东西由于被包括所以靠近中央区域了

2.总结涉及到的参数

> stride（滑动窗口步长）：一般为1
>
> 卷积核尺寸：一般为3x3
>
> padding边缘填充
>
> 卷积核个数
>
> filter滤波器个数？

3.卷积是分层的，在一次提取特征中，会有多层的提取

随着层数越来越深，得到的信息越来越全局，越为高度汇总

但是并不意味着越深的网络越好，对于小目标的检测就不好了

理论上卷积的次数越多越好

4.卷积参数共享：

在一个filter中，卷积的权重矩阵是保持不变的

输入32x32x3的图像，继续使用10个5x5x3的filter来进行卷积，所需的权重参数有多少个？

个数=5x5x3x10 = 750，

等等**还有重要的偏置参数b**！10个filter，每个filter的偏置参数都为1，所以总的参数个数为760！

并且更为重要的一点，他的参数数量就是取决于卷积核的，即便输入大小变大了，他的参数数量仍不会变

## 池化层

### MAX Pooling

**池化层就是对卷积所提取特征的筛选！**

在特征图矩阵里，数值越大代表着所提取的特征越好越强

池化的目的就是要为了去掉数值特别小的特征，**保留数值大的特征**。但是是在几x几区域取最大值，这是自己确定的

 **关于其大小：**

![image-20240913171158080](C:\Users\zbw\AppData\Roaming\Typora\typora-user-images\image-20240913171158080.png)

channel不会变，因为经过64个filter就会得到64个特征图

经过池化层H与W均变为了原来的一半，整体就变为了1/4

**这一过程也叫做下采样。下采样要一步一步的去做，先1/2再1/2，而不能直接1/4**

### Avg Pooling

这种方法是平均池化，是计算特征图中一个区域的平均值，这种操作几乎不用

**都是用的最大池化max pooling**



## 一点拓展：关于transformer

cnn的拓展性很强，能做的拓展非常多，简单

而transformer的拓展比较难



## 框架总结

![image-20240913172823263](C:\Users\zbw\AppData\Roaming\Typora\typora-user-images\image-20240913172823263.png)

relu为一个非线性的激活函数

最终输出的是特征图是三维的，在得到特征图后再经过一个全连接就可以得到具体的数值输出。

如上的图为7层的CNN，pooling不算层，CONV算一层，还有最后的一个FC全连接

即带权重的算作一层

![image-20240913175427547](C:\Users\zbw\AppData\Roaming\Typora\typora-user-images\image-20240913175427547.png)

一层卷积中可以使用多个卷积核（filter），有几个卷积核就会得到多少个特征图



## 关于标准化

最初的输入经过标准化，在经过每次卷积后还要再进行一次标准化（BN）

因为经过卷积可能会有些异常，不稳定，这时候应用BN会稳定回来

标准化公式：

（x-μ）/s，这是传统的标准化公式。

BN会根据数据特点学习新的标准化公式

## 经典网络1.---AlexNet

![image-20240913175626429](C:\Users\zbw\AppData\Roaming\Typora\typora-user-images\image-20240913175626429.png)

## 经典网络2---VGG

![image-20240913175817088](C:\Users\zbw\AppData\Roaming\Typora\typora-user-images\image-20240913175817088.png)

经过池化会损失一些特征，那么在vgg中经过池化后，他让特征图个数翻倍来弥补

即channel这个维度x2.

## 经典网络3---Resnet

![image-20240913180457574](C:\Users\zbw\AppData\Roaming\Typora\typora-user-images\image-20240913180457574.png)

解决了层数越多效果反而不好的情况

至少不比原来差的解决思想！

